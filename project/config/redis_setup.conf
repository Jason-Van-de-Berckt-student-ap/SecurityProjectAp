# Redis Configuration for EASM Application
# This file contains Redis setup instructions and configuration

# ============================================================================
# REDIS INSTALLATION & SETUP
# ============================================================================

# Windows Installation:
# 1. Download Redis for Windows from: https://github.com/microsoftarchive/redis/releases
# 2. Extract and run redis-server.exe
# 3. Or use Docker: docker run -d -p 6379:6379 redis:latest

# Linux Installation:
# sudo apt-get update
# sudo apt-get install redis-server
# sudo systemctl start redis-server
# sudo systemctl enable redis-server

# macOS Installation:
# brew install redis
# brew services start redis

# ============================================================================
# REDIS CONFIGURATION
# ============================================================================

# Basic Redis Configuration (redis.conf)
# Uncomment and modify these settings as needed:

# Network Settings
# bind 127.0.0.1
# port 6379
# timeout 0
# tcp-keepalive 300

# Memory Settings
# maxmemory 256mb
# maxmemory-policy allkeys-lru

# Persistence Settings
# save 900 1
# save 300 10
# save 60 10000
# rdbcompression yes
# rdbchecksum yes
# dbfilename dump.rdb
# dir /var/lib/redis

# Security Settings
# requirepass your_redis_password
# rename-command FLUSHDB ""
# rename-command FLUSHALL ""

# ============================================================================
# EASM APPLICATION REDIS SETTINGS
# ============================================================================

# Add these to your .env file or config.py:

REDIS_HOST = 'localhost'
REDIS_PORT = 6379
REDIS_DB = 0
REDIS_PASSWORD = None  # Set password if required
REDIS_DECODE_RESPONSES = True

# Connection Pool Settings
REDIS_MAX_CONNECTIONS = 20
REDIS_RETRY_ON_TIMEOUT = True
REDIS_SOCKET_TIMEOUT = 5
REDIS_SOCKET_CONNECT_TIMEOUT = 5

# Cache TTL Settings (in seconds)
CACHE_TTL_DNS = 1800      # 30 minutes
CACHE_TTL_SUBDOMAIN = 3600 # 1 hour
CACHE_TTL_DOMAIN = 7200   # 2 hours
CACHE_TTL_VULN = 1800     # 30 minutes

# ============================================================================
# DOCKER COMPOSE SETUP
# ============================================================================

# Create docker-compose.yml for Redis:
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./redis.conf:/usr/local/etc/redis/redis.conf
    command: redis-server /usr/local/etc/redis/redis.conf
    restart: unless-stopped
    networks:
      - easm_network

  redis-commander:
    image: rediscommander/redis-commander:latest
    environment:
      - REDIS_HOSTS=local:redis:6379
    ports:
      - "8081:8081"
    depends_on:
      - redis
    networks:
      - easm_network

volumes:
  redis_data:

networks:
  easm_network:
    driver: bridge

# ============================================================================
# PRODUCTION REDIS CONFIGURATION
# ============================================================================

# Production redis.conf settings:

# Security
protected-mode yes
requirepass your_strong_password_here

# Memory optimization
maxmemory 1gb
maxmemory-policy allkeys-lru
maxmemory-samples 5

# Persistence
save 900 1
save 300 10
save 60 10000
stop-writes-on-bgsave-error yes
rdbcompression yes
rdbchecksum yes

# Networking
tcp-backlog 511
tcp-keepalive 300
timeout 0

# Logging
loglevel notice
logfile /var/log/redis/redis-server.log

# Slow log
slowlog-log-slower-than 10000
slowlog-max-len 128

# Client output buffer limits
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit replica 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60

# ============================================================================
# MONITORING & MAINTENANCE
# ============================================================================

# Redis CLI Commands for monitoring:
# redis-cli INFO memory
# redis-cli INFO replication
# redis-cli INFO stats
# redis-cli MONITOR
# redis-cli --latency
# redis-cli --latency-history

# Maintenance commands:
# redis-cli BGREWRITEAOF  # Rewrite AOF file
# redis-cli BGSAVE        # Background save
# redis-cli FLUSHDB       # Clear current database
# redis-cli CONFIG GET *  # Get all configuration

# ============================================================================
# BACKUP STRATEGY
# ============================================================================

# Automated backup script (backup_redis.sh):
#!/bin/bash
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backup/redis"
mkdir -p $BACKUP_DIR

# Create backup
redis-cli --rdb $BACKUP_DIR/dump_$DATE.rdb

# Compress backup
gzip $BACKUP_DIR/dump_$DATE.rdb

# Remove backups older than 7 days
find $BACKUP_DIR -name "dump_*.rdb.gz" -mtime +7 -delete

echo "Redis backup completed: $BACKUP_DIR/dump_$DATE.rdb.gz"

# Add to crontab for daily backups:
# 0 2 * * * /path/to/backup_redis.sh

# ============================================================================
# TROUBLESHOOTING
# ============================================================================

# Common issues and solutions:

# 1. Connection refused:
#    - Check if Redis is running: systemctl status redis
#    - Check port: netstat -tlnp | grep 6379
#    - Check firewall settings

# 2. Out of memory:
#    - Check memory usage: redis-cli INFO memory
#    - Increase maxmemory setting
#    - Review cache TTL settings

# 3. Slow performance:
#    - Check slow queries: redis-cli SLOWLOG GET 10
#    - Monitor with: redis-cli --latency
#    - Check for memory swapping

# 4. High CPU usage:
#    - Check for expensive operations
#    - Monitor with: redis-cli INFO cpu
#    - Consider using Redis Cluster for high load

# ============================================================================
# SCALING CONSIDERATIONS
# ============================================================================

# For high-traffic scenarios:

# 1. Redis Cluster Setup:
#    - Distribute data across multiple Redis nodes
#    - Automatic failover and load distribution

# 2. Redis Sentinel:
#    - High availability with automatic failover
#    - Monitor master/replica health

# 3. Read Replicas:
#    - Separate read and write operations
#    - Scale read capacity horizontally

# 4. Connection Pooling:
#    - Use connection pools in application
#    - Limit concurrent connections

# ============================================================================
# INTEGRATION WITH EASM
# ============================================================================

# Update your Flask app configuration:
import redis
from redis.connection import ConnectionPool

class Config:
    # Redis Configuration
    REDIS_URL = os.environ.get('REDIS_URL') or 'redis://localhost:6379/0'
    
    # Create connection pool
    REDIS_POOL = ConnectionPool.from_url(
        REDIS_URL,
        max_connections=20,
        retry_on_timeout=True,
        socket_timeout=5,
        socket_connect_timeout=5
    )
    
    # Cache settings
    CACHE_TYPE = 'redis'
    CACHE_REDIS_URL = REDIS_URL
    CACHE_DEFAULT_TIMEOUT = 300

# Initialize Redis in your app:
redis_client = redis.Redis(connection_pool=Config.REDIS_POOL)

# Test Redis connection:
try:
    redis_client.ping()
    print("Redis connection successful")
except redis.ConnectionError:
    print("Redis connection failed")

# ============================================================================
# MONITORING DASHBOARD
# ============================================================================

# Redis metrics to monitor:
# - Memory usage
# - Connected clients
# - Operations per second
# - Cache hit ratio
# - Slow queries
# - Keyspace statistics

# Integration with monitoring dashboard:
def get_redis_stats():
    info = redis_client.info()
    return {
        'memory_used': info['used_memory_human'],
        'memory_peak': info['used_memory_peak_human'],
        'connected_clients': info['connected_clients'],
        'total_commands_processed': info['total_commands_processed'],
        'ops_per_sec': info.get('instantaneous_ops_per_sec', 0),
        'keyspace_hits': info.get('keyspace_hits', 0),
        'keyspace_misses': info.get('keyspace_misses', 0)
    }
